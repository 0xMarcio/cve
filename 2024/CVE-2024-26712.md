### [CVE-2024-26712](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2024-26712)
![](https://img.shields.io/static/v1?label=Product&message=Linux&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=5.4%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=5ce93076d8ee2a0fac3ad4adbd2e91b6197146db%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=663c0c9496a69f80011205ba3194049bcafd681d%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=n%2Fa&color=blue)

### Description

In the Linux kernel, the following vulnerability has been resolved:powerpc/kasan: Fix addr error caused by page alignmentIn kasan_init_region, when k_start is not page aligned, at the begin offor loop, k_cur = k_start & PAGE_MASK is less than k_start, and then`va = block + k_cur - k_start` is less than block, the addr va is invalid,because the memory address space from va to block is not alloced bymemblock_alloc, which will not be reserved by memblock_reserve later, itwill be used by other places.As a result, memory overwriting occurs.for example:int __init __weak kasan_init_region(void *start, size_t size){[...]	/* if say block(dcd97000) k_start(feef7400) k_end(feeff3fe) */	block = memblock_alloc(k_end - k_start, PAGE_SIZE);	[...]	for (k_cur = k_start & PAGE_MASK; k_cur < k_end; k_cur += PAGE_SIZE) {		/* at the begin of for loop		 * block(dcd97000) va(dcd96c00) k_cur(feef7000) k_start(feef7400)		 * va(dcd96c00) is less than block(dcd97000), va is invalid		 */		void *va = block + k_cur - k_start;		[...]	}[...]}Therefore, page alignment is performed on k_start beforememblock_alloc() to ensure the validity of the VA address.

### POC

#### Reference
No PoCs from references.

#### Github
- https://github.com/fkie-cad/nvd-json-data-feeds

