### [CVE-2025-29783](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2025-29783)
![](https://img.shields.io/static/v1?label=Product&message=vllm&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3E%3D%200.6.5%2C%20%3C%200.8.0%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-502%3A%20Deserialization%20of%20Untrusted%20Data&color=brightgreen)

### Description

vLLM is a high-throughput and memory-efficient inference and serving engine for LLMs. When vLLM is configured to use Mooncake, unsafe deserialization exposed directly over ZMQ/TCP on all network interfaces will allow attackers to execute remote code on distributed hosts. This is a remote code execution vulnerability impacting any deployments using Mooncake to distribute KV across distributed hosts. This vulnerability is fixed in 0.8.0.

### POC

#### Reference
No PoCs from references.

#### Github
- https://github.com/honysyang/eleaipoc

