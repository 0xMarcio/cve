### [CVE-2025-48956](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2025-48956)
![](https://img.shields.io/static/v1?label=Product&message=vllm&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=%3E%3D%200.1.0%2C%20%3C%200.10.1.1%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=CWE-400%3A%20Uncontrolled%20Resource%20Consumption&color=brightgreen)

### Description

vLLM is an inference and serving engine for large language models (LLMs). From 0.1.0 to before 0.10.1.1, a Denial of Service (DoS) vulnerability can be triggered by sending a single HTTP GET request with an extremely large header to an HTTP endpoint. This results in server memory exhaustion, potentially leading to a crash or unresponsiveness. The attack does not require authentication, making it exploitable by any remote user. This vulnerability is fixed in 0.10.1.1.

### POC

#### Reference
No PoCs from references.

#### Github
- https://github.com/fkie-cad/nvd-json-data-feeds

