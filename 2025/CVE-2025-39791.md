### [CVE-2025-39791](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2025-39791)
![](https://img.shields.io/static/v1?label=Product&message=Linux&color=blue)
![](https://img.shields.io/static/v1?label=Version&message=&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=6.10%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Version&message=f211268ed1f9bdf48f06a3ead5f5d88437450579%20&color=brightgreen)
![](https://img.shields.io/static/v1?label=Vulnerability&message=n%2Fa&color=blue)

### Description

In the Linux kernel, the following vulnerability has been resolved:dm: dm-crypt: Do not partially accept write BIOs with zoned targetsRead and write operations issued to a dm-crypt target may be splitaccording to the dm-crypt internal limits defined by the max_read_sizeand max_write_size module parameters (default is 128 KB). The intent isto improve processing time of large BIOs by splitting them into smalleroperations that can be parallelized on different CPUs.For zoned dm-crypt targets, this BIO splitting is still done but withoutthe parallel execution to ensure that the issuing order of writeoperations to the underlying devices remains sequential. However, thesplitting itself causes other problems:1) Since dm-crypt relies on the block layer zone write plugging to   handle zone append emulation using regular write operations, the   reminder of a split write BIO will always be plugged into the target   zone write plugged. Once the on-going write BIO finishes, this   reminder BIO is unplugged and issued from the zone write plug work.   If this reminder BIO itself needs to be split, the reminder will be   re-issued and plugged again, but that causes a call to a   blk_queue_enter(), which may block if a queue freeze operation was   initiated. This results in a deadlock as DM submission still holds   BIOs that the queue freeze side is waiting for.2) dm-crypt relies on the emulation done by the block layer using   regular write operations for processing zone append operations. This   still requires to properly return the written sector as the BIO   sector of the original BIO. However, this can be done correctly only   and only if there is a single clone BIO used for processing the   original zone append operation issued by the user. If the size of a   zone append operation is larger than dm-crypt max_write_size, then   the orginal BIO will be split and processed as a chain of regular   write operations. Such chaining result in an incorrect written sector   being returned to the zone append issuer using the original BIO   sector.  This in turn results in file system data corruptions using   xfs or btrfs.Fix this by modifying get_max_request_size() to always return the sizeof the BIO to avoid it being split with dm_accpet_partial_bio() incrypt_map(). get_max_request_size() is renamed toget_max_request_sectors() to clarify the unit of the value returnedand its interface is changed to take a struct dm_target pointer and apointer to the struct bio being processed. In addition to this change,to ensure that crypt_alloc_buffer() works correctly, set the dm-cryptdevice max_hw_sectors limit to be at mostBIO_MAX_VECS << PAGE_SECTORS_SHIFT (1 MB with a 4KB page architecture).This forces DM core to split write BIOs before passing them tocrypt_map(), and thus guaranteeing that dm-crypt can always accept anentire write BIO without needing to split it.This change does not have any effect on the read path of dm-crypt. Readoperations can still be split and the BIO fragments processed inparallel. There is also no impact on the performance of the write pathgiven that all zone write BIOs were already processed inline instead ofin parallel.This change also does not affect in any way regular dm-crypt blockdevices.

### POC

#### Reference
No PoCs from references.

#### Github
- https://github.com/w4zu/Debian_security

